1) Start by filtering unnecessary records from the full text file (which contains more than 5.3 million records). For example, to filter only records belonging to the city of São Paulo and then count the resulting lines:

	awk 'substr($0,212,7)=="3550308" {print}' DADOS_ENEM_2011.TXT >enem_cidade_sao_paulo.txt 
	wc -l enem_cidade_sao_paulo.txt 

To filter (and count) records belonging to the state of São Paulo:

	awk 'substr($0,369,2)=="SP" {print}' DADOS_ENEM_2011.TXT >enem_estado_sao_paulo.txt 
	wc -l enem_estado_sao_paulo.txt 


2) Now you can also filter schools belonging to the city and state of São Paulo, respectively:

	awk 'substr($0,4,7)=="3550308" {print}' sudeste.csv >escolas_cidade_sao_paulo.csv 
	wc -l escolas_cidade_sao_paulo.csv

	awk 'substr($0,1,2)=="SP" {print}' sudeste.csv >escolas_estado_sao_paulo.csv 
	wc -l escolas_estado_sao_paulo.csv


3) Using any appropriate tool (e.g. pgAdmin3), create an empty Postgres database named 'inep_temp'.


4) Create the initial tables, by loading and running the following SQL script in Postgres:

	ETL/1_create_tables.sql


5) From the application's root folder, load both school and Enem data into Postgres, using pgloader:

	~/pgloader/pgloader.PY -vsc ETL/schools_pgloader.conf
	~/pgloader/pgloader.PY -m 4 -vsc ETL/enem_pgloader.conf

PS: Enem data takes a while to execute (> 30 minutes).


6) Create and load all remaining tables/views, following the steps from 2 to 8:

	ETL/2_create_schools_dimension.sql
	ETL/3_create_nc_score_dimension.sql
	ETL/4_create_hc_score_dimension.sql
	ETL/5_create_lc_score_dimension.sql
	ETL/6_create_mt_score_dimension.sql
	ETL/7_create_facts_table.sql
	ETL/8_create_views.sql
